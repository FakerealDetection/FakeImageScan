# FakeImageScan  
**Beyond Visual Artifacts: Detecting AI-Generated Images via Model Affinity and Task Difficulty**

FakeImageScan is a **dual-pathway framework** for detecting AI-generated images produced by **GANs and diffusion models**.  
Instead of relying on fragile visual artifacts, FakeImageScan exploits **model affinity** and **task difficulty** signals to achieve **robust, generator-agnostic detection**.

---

## üìå Key Idea

> **AI-generated images are more compatible with AI models than real images.**

FakeImageScan detects this asymmetry by jointly measuring:

- **How well AI models perform on an image** (*Model Affinity*), and  
- **How difficult the image should be for those tasks** (*Task Difficulty*).

A mismatch between these two signals provides a powerful cue for identifying synthetic images.

---

## üîç Framework Overview

FakeImageScan consists of **two complementary pathways**:

### 1Ô∏è‚É£ Model Affinity Pathway (Performance Signals)

Measures how confidently AI models process an image.

- **Inpainting Accuracy (A)**  
  Evaluates reconstruction fidelity using **SSIM** after masked inpainting.  
  AI-generated images tend to be reconstructed with unusually high accuracy.

- **Segmentation Confidence (S)**  
  Measures average **per-pixel confidence** from a semantic segmentation model.  
  Synthetic images often produce over-confident and spatially uniform predictions.

---

### 2Ô∏è‚É£ Task Difficulty Pathway (Context Signals)

Estimates how challenging the image should be for vision models.

- **Pixel Naturalness (N)**  
  Quantifies pixel-level predictability using global and local probability models.

- **Image Complexity (C)**  
  Combines multiple structural and statistical cues, including:
  - Edge density  
  - Texture variance  
  - Entropy  
  - Frequency-domain characteristics  

---

## üß† Feature Vector

For each image **I**, FakeImageScan extracts a **4D feature vector**:

